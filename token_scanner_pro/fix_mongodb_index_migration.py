"""
Script de Migration MongoDB - Correction Urgente Index

Ce script corrige le probl√®me critique d'index avec mauvais noms de champs.

PROBL√àME:
- Index actuel: (address, chain)
- Champs stock√©s: (token_address, token_chain)
- R√©sultat: Tous les inserts √©chouent avec E11000 duplicate key error

SOLUTION:
1. Supprimer l'ancien index incorrect
2. Nettoyer les documents avec address/chain null
3. Cr√©er le nouvel index correct

Usage:
    python fix_mongodb_index_migration.py
"""

from mongodb_manager import MongoDBManager
from logger import logger
import sys


def fix_index_migration():
    """Migration compl√®te pour corriger les index"""

    try:
        db = MongoDBManager()
        logger.info("=" * 70)
        logger.info("üîß MIGRATION MONGODB - CORRECTION INDEX CRITIQUE")
        logger.info("=" * 70)

        # ==================== √âTAPE 1: LISTER LES INDEX ACTUELS ====================
        logger.info("\nüìã √âTAPE 1: Liste des index actuels sur scanned_tokens")

        existing_indexes = list(db.scanned_tokens.list_indexes())
        logger.info(f"Nombre d'index: {len(existing_indexes)}")

        for idx in existing_indexes:
            logger.info(f"  ‚Ä¢ {idx['name']}: {idx.get('key', {})}")

        # ==================== √âTAPE 2: SUPPRIMER ANCIEN INDEX INCORRECT ====================
        logger.info("\nüóëÔ∏è  √âTAPE 2: Suppression des index incorrects")

        indexes_to_drop = []

        for idx in existing_indexes:
            idx_name = idx['name']
            idx_key = idx.get('key', {})

            # Ignorer l'index _id_ (obligatoire)
            if idx_name == '_id_':
                continue

            # V√©rifier si l'index utilise les mauvais noms de champs
            if 'address' in idx_key and 'token_address' not in idx_key:
                logger.warning(f"‚ö†Ô∏è  Index incorrect d√©tect√©: {idx_name} (utilise 'address' au lieu de 'token_address')")
                indexes_to_drop.append(idx_name)

            if 'chain' in idx_key and 'token_chain' not in idx_key:
                logger.warning(f"‚ö†Ô∏è  Index incorrect d√©tect√©: {idx_name} (utilise 'chain' au lieu de 'token_chain')")
                if idx_name not in indexes_to_drop:
                    indexes_to_drop.append(idx_name)

        # Supprimer les index incorrects
        for idx_name in indexes_to_drop:
            try:
                logger.info(f"üóëÔ∏è  Suppression de l'index: {idx_name}")
                db.scanned_tokens.drop_index(idx_name)
                logger.info(f"‚úÖ Index {idx_name} supprim√©")
            except Exception as e:
                logger.error(f"‚ùå Erreur suppression {idx_name}: {e}")

        if not indexes_to_drop:
            logger.info("‚úÖ Aucun index incorrect trouv√©")

        # ==================== √âTAPE 3: NETTOYER DOCUMENTS INVALIDES ====================
        logger.info("\nüßπ √âTAPE 3: Nettoyage des documents invalides")

        # Requ√™te pour trouver documents avec address/chain/token_address/token_chain null
        invalid_query = {
            "$or": [
                {"token_address": None},
                {"token_chain": None},
                {"token_address": {"$exists": False}},
                {"token_chain": {"$exists": False}},
                {"address": None},
                {"chain": None}
            ]
        }

        invalid_count = db.scanned_tokens.count_documents(invalid_query)

        if invalid_count > 0:
            logger.warning(f"‚ö†Ô∏è  {invalid_count} document(s) invalide(s) trouv√©(s)")

            # Afficher √©chantillon
            samples = list(db.scanned_tokens.find(invalid_query).limit(3))
            logger.info("\nüìã √âchantillon de documents invalides:")
            for i, doc in enumerate(samples, 1):
                logger.info(f"  {i}. _id: {doc.get('_id')}")
                logger.info(f"     token_address: {doc.get('token_address')}")
                logger.info(f"     token_chain: {doc.get('token_chain')}")
                logger.info(f"     address: {doc.get('address')}")
                logger.info(f"     chain: {doc.get('chain')}")

            # Supprimer
            logger.info(f"\nüóëÔ∏è  Suppression de {invalid_count} document(s) invalide(s)...")
            result = db.scanned_tokens.delete_many(invalid_query)
            logger.info(f"‚úÖ {result.deleted_count} document(s) supprim√©(s)")
        else:
            logger.info("‚úÖ Aucun document invalide trouv√©")

        # ==================== √âTAPE 4: CR√âER NOUVEL INDEX CORRECT ====================
        logger.info("\nüî® √âTAPE 4: Cr√©ation du nouvel index correct")

        try:
            # Cr√©er index unique sur (token_address, token_chain)
            logger.info("Cr√©ation de l'index: (token_address, token_chain) UNIQUE")
            db.scanned_tokens.create_index(
                [("token_address", 1), ("token_chain", 1)],
                unique=True,
                name="idx_token_address_chain_unique"
            )
            logger.info("‚úÖ Index idx_token_address_chain_unique cr√©√© avec succ√®s")
        except Exception as e:
            if "already exists" in str(e).lower():
                logger.info("‚è≠Ô∏è  Index idx_token_address_chain_unique existe d√©j√†")
            else:
                logger.error(f"‚ùå Erreur cr√©ation index: {e}")
                raise

        # Cr√©er les autres index importants
        logger.info("\nüî® Cr√©ation des index suppl√©mentaires...")

        # Index sur scanned_at (pour tri chronologique)
        try:
            db.scanned_tokens.create_index(
                [("scanned_at", -1)],
                name="idx_scanned_at_desc"
            )
            logger.info("‚úÖ Index idx_scanned_at_desc cr√©√©")
        except Exception as e:
            if "already exists" in str(e).lower():
                logger.info("‚è≠Ô∏è  Index idx_scanned_at_desc existe d√©j√†")

        # Index sur token_chain (pour filtrage)
        try:
            db.scanned_tokens.create_index(
                "token_chain",
                name="idx_token_chain"
            )
            logger.info("‚úÖ Index idx_token_chain cr√©√©")
        except Exception as e:
            if "already exists" in str(e).lower():
                logger.info("‚è≠Ô∏è  Index idx_token_chain existe d√©j√†")

        # Index sur is_safe (pour filtrage)
        try:
            db.scanned_tokens.create_index(
                "is_safe",
                name="idx_is_safe"
            )
            logger.info("‚úÖ Index idx_is_safe cr√©√©")
        except Exception as e:
            if "already exists" in str(e).lower():
                logger.info("‚è≠Ô∏è  Index idx_is_safe existe d√©j√†")

        # ==================== √âTAPE 5: V√âRIFICATION FINALE ====================
        logger.info("\n‚úÖ √âTAPE 5: V√©rification finale")

        final_indexes = list(db.scanned_tokens.list_indexes())
        logger.info(f"\nüìä Index finaux sur scanned_tokens ({len(final_indexes)} index):")

        for idx in final_indexes:
            idx_name = idx['name']
            idx_key = idx.get('key', {})
            is_unique = idx.get('unique', False)
            unique_str = " [UNIQUE]" if is_unique else ""
            logger.info(f"  ‚úÖ {idx_name}: {idx_key}{unique_str}")

        # V√©rifier qu'aucun index incorrect ne reste
        has_incorrect = False
        for idx in final_indexes:
            idx_key = idx.get('key', {})
            if idx['name'] != '_id_':  # Ignorer _id_
                if 'address' in idx_key and 'token_address' not in idx_key:
                    logger.error(f"‚ùå Index incorrect toujours pr√©sent: {idx['name']}")
                    has_incorrect = True
                if 'chain' in idx_key and 'token_chain' not in idx_key:
                    logger.error(f"‚ùå Index incorrect toujours pr√©sent: {idx['name']}")
                    has_incorrect = True

        if not has_incorrect:
            logger.info("\n‚úÖ Aucun index incorrect restant")

        # Compter les documents valides
        valid_count = db.scanned_tokens.count_documents({})
        logger.info(f"\nüìä Documents dans scanned_tokens: {valid_count}")

        logger.info("\n" + "=" * 70)
        logger.info("‚úÖ MIGRATION TERMIN√âE AVEC SUCC√àS !")
        logger.info("=" * 70)

        logger.info("\nüìã PROCHAINES √âTAPES:")
        logger.info("1. Red√©marrez votre application Flask")
        logger.info("2. Les nouveaux tokens devraient s'ins√©rer sans erreur E11000")
        logger.info("3. V√©rifiez les logs: 'üíæ X/20 tokens stock√©s dans la BDD' (X devrait √™tre proche de 20)")

        return True

    except Exception as e:
        logger.error(f"‚ùå Erreur critique durant la migration: {e}", exc_info=True)
        return False


if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("üîß MIGRATION MONGODB - CORRECTION INDEX CRITIQUE")
    print("=" * 70)
    print("\nCe script va:")
    print("1. Supprimer les index incorrects (address, chain)")
    print("2. Nettoyer les documents invalides")
    print("3. Cr√©er les nouveaux index corrects (token_address, token_chain)")
    print("\n‚ö†Ô∏è  L'application doit √™tre ARR√äT√âE pendant la migration!")
    print("=" * 70)

    response = input("\nContinuer? (oui/non): ").strip().lower()

    if response not in ['oui', 'yes', 'o', 'y']:
        print("‚ùå Migration annul√©e")
        sys.exit(0)

    print("\nüöÄ D√©marrage de la migration...\n")

    success = fix_index_migration()

    if success:
        print("\n" + "=" * 70)
        print("‚úÖ MIGRATION R√âUSSIE !")
        print("=" * 70)
        print("\nVous pouvez maintenant red√©marrer votre application.")
        sys.exit(0)
    else:
        print("\n" + "=" * 70)
        print("‚ùå MIGRATION √âCHOU√âE !")
        print("=" * 70)
        print("\nV√©rifiez les logs ci-dessus pour plus de d√©tails.")
        sys.exit(1)
